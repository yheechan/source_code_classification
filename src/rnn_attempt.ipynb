{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import data\n",
    "import utils\n",
    "import info_recorder as ir\n",
    "import data_loader as dl\n",
    "import initializer as init\n",
    "import trainer as tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, size_info, size_dict = data.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceCode_np = df.sourceCode.values\n",
    "codeClass_np = df.classLabel.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize, build vocabulary, encode tokens\n",
    "print(\"Tokenizing...\\n\")\n",
    "tokenized_sourceCodes, ch2idx, max_len = utils.tokenize(sourceCode_np)\n",
    "input_ids = utils.encode(tokenized_sourceCodes, ch2idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir.record_ch2idx(ch2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_class2idx, class2idx, num_classes = utils.tokenize_encode_class(codeClass_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
    "    input_ids, encoded_class2idx, test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to PyTorch DataLoader\n",
    "train_dataloader, val_dataloader = dl.data_loader(train_inputs, val_inputs, train_labels, val_labels, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('rnnEmbLay/tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   2.975701   |  2.839595  |   11.93   |   99.74  \n",
      "   2    |   2.713847   |  2.507514  |   21.07   |  100.65  \n",
      "   3    |   2.420895   |  2.288824  |   28.70   |  100.93  \n",
      "   4    |   2.210128   |  2.048845  |   35.71   |  101.19  \n",
      "   5    |   1.954627   |  1.778286  |   45.06   |  101.27  \n",
      "   6    |   1.663059   |  1.502168  |   54.57   |  101.28  \n",
      "   7    |   1.400794   |  1.252069  |   62.84   |  101.27  \n",
      "   8    |   1.207395   |  1.102171  |   67.40   |  101.28  \n",
      "   9    |   1.071432   |  1.004654  |   70.34   |  101.31  \n",
      "  10    |   0.968053   |  0.927908  |   72.74   |  101.35  \n",
      "  11    |   0.889113   |  0.871712  |   74.51   |  102.06  \n",
      "  12    |   0.827378   |  0.842852  |   75.36   |  101.34  \n",
      "  13    |   0.776249   |  0.805540  |   76.10   |  101.30  \n",
      "  14    |   0.730918   |  0.785301  |   76.96   |  101.30  \n",
      "  15    |   0.693305   |  0.756443  |   78.03   |  101.34  \n",
      "  16    |   0.659528   |  0.741232  |   78.60   |  101.28  \n",
      "  17    |   0.631084   |  0.730771  |   78.98   |  101.28  \n",
      "  18    |   0.601558   |  0.716176  |   79.43   |  101.34  \n",
      "  19    |   0.577589   |  0.708772  |   79.60   |  101.36  \n",
      "  20    |   0.554897   |  0.696108  |   80.20   |  101.35  \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 80.20%.\n"
     ]
    }
   ],
   "source": [
    "# CNN-rand: Word vectors are randomly initialized.\n",
    "tn.set_seed(42)\n",
    "cnn_rand, optimizer = init.initilize_model(device=device,\n",
    "                                           vocab_size=len(ch2idx),\n",
    "                                           embed_dim=20,\n",
    "                                           hidden_size=100,\n",
    "                                           num_classes=len(class2idx),\n",
    "                                           n_layers=3,\n",
    "                                           dropout=0.2,\n",
    "                                           learning_rate=0.25,\n",
    "                                           optimizerName=\"Adadelta\",\n",
    "                                           modelType=\"RNN\")\n",
    "                                        \n",
    "tn.train(device, cnn_rand, optimizer, train_dataloader, 'EMB_test1', writer, val_dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   2.879673   |  2.556890  |   20.29   |  100.49  \n",
      "   2    |   2.393848   |  2.247700  |   31.07   |  101.26  \n",
      "   3    |   2.115112   |  1.945344  |   39.82   |  101.44  \n",
      "   4    |   1.831760   |  1.673026  |   49.29   |  101.47  \n",
      "   5    |   1.518497   |  1.303801  |   61.53   |  101.51  \n",
      "   6    |   1.230478   |  1.106801  |   67.41   |  101.46  \n",
      "   7    |   1.047943   |  0.961553  |   71.72   |  101.46  \n",
      "   8    |   0.929843   |  0.884785  |   74.03   |  101.48  \n",
      "   9    |   0.846466   |  0.838950  |   75.44   |  101.45  \n",
      "  10    |   0.785719   |  0.790321  |   76.81   |  101.51  \n",
      "  11    |   0.732973   |  0.767378  |   77.40   |  101.51  \n",
      "  12    |   0.690738   |  0.743681  |   78.32   |  101.51  \n",
      "  13    |   0.654648   |  0.714335  |   79.21   |  101.48  \n",
      "  14    |   0.619500   |  0.701817  |   79.68   |  101.50  \n",
      "  15    |   0.587777   |  0.693522  |   79.76   |  101.47  \n",
      "  16    |   0.562096   |  0.699732  |   80.06   |  101.49  \n",
      "  17    |   0.537251   |  0.685872  |   80.51   |  101.45  \n",
      "  18    |   0.514373   |  0.679837  |   80.45   |  101.52  \n",
      "  19    |   0.492568   |  0.679364  |   81.10   |  101.50  \n",
      "  20    |   0.474630   |  0.662791  |   81.36   |  101.54  \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 81.36%.\n"
     ]
    }
   ],
   "source": [
    "# CNN-rand: Word vectors are randomly initialized.\n",
    "tn.set_seed(42)\n",
    "cnn_rand, optimizer = init.initilize_model(device=device,\n",
    "                                           vocab_size=len(ch2idx),\n",
    "                                           embed_dim=50,\n",
    "                                           hidden_size=100,\n",
    "                                           num_classes=len(class2idx),\n",
    "                                           n_layers=3,\n",
    "                                           dropout=0.2,\n",
    "                                           learning_rate=0.25,\n",
    "                                           optimizerName=\"Adadelta\",\n",
    "                                           modelType=\"RNN\")\n",
    "                                        \n",
    "tn.train(device, cnn_rand, optimizer, train_dataloader, 'EMB_test2', writer, val_dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   2.844391   |  2.552644  |   20.14   |  100.97  \n",
      "   2    |   2.383381   |  2.275306  |   29.70   |  101.82  \n",
      "   3    |   2.096223   |  1.933571  |   39.77   |  101.92  \n",
      "   4    |   1.793507   |  1.610627  |   50.73   |  102.00  \n",
      "   5    |   1.424716   |  1.221779  |   63.68   |  101.98  \n",
      "   6    |   1.162608   |  1.057564  |   68.75   |  101.97  \n",
      "   7    |   1.000601   |  0.966052  |   71.90   |  101.97  \n",
      "   8    |   0.896507   |  0.882964  |   74.20   |  102.03  \n",
      "   9    |   0.821875   |  0.814919  |   76.19   |  102.06  \n",
      "  10    |   0.761787   |  0.788362  |   76.99   |  102.02  \n",
      "  11    |   0.714178   |  0.773136  |   77.40   |  102.05  \n",
      "  12    |   0.673500   |  0.739848  |   78.59   |  102.01  \n",
      "  13    |   0.635817   |  0.743026  |   78.59   |  101.99  \n",
      "  14    |   0.604778   |  0.699512  |   79.73   |  101.99  \n",
      "  15    |   0.575052   |  0.692936  |   80.00   |  101.97  \n",
      "  16    |   0.549426   |  0.684150  |   80.28   |  101.99  \n",
      "  17    |   0.525783   |  0.689686  |   80.52   |  102.03  \n",
      "  18    |   0.501570   |  0.674959  |   80.80   |  102.05  \n",
      "  19    |   0.483570   |  0.673618  |   81.15   |  102.01  \n",
      "  20    |   0.465420   |  0.682079  |   80.89   |  102.04  \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 81.15%.\n"
     ]
    }
   ],
   "source": [
    "# CNN-rand: Word vectors are randomly initialized.\n",
    "tn.set_seed(42)\n",
    "cnn_rand, optimizer = init.initilize_model(device=device,\n",
    "                                           vocab_size=len(ch2idx),\n",
    "                                           embed_dim=70,\n",
    "                                           hidden_size=100,\n",
    "                                           num_classes=len(class2idx),\n",
    "                                           n_layers=3,\n",
    "                                           dropout=0.2,\n",
    "                                           learning_rate=0.25,\n",
    "                                           optimizerName=\"Adadelta\",\n",
    "                                           modelType=\"RNN\")\n",
    "                                        \n",
    "tn.train(device, cnn_rand, optimizer, train_dataloader, 'EMB_test3', writer, val_dataloader, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
